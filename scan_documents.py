from docx import Document
from PyPDF2 import PdfReader
import pypandoc
from aiogram import Bot
import os
from gpt_gimini import sverka_vac_and_resume_json
import asyncio
from funcs import format_candidate_json_str
from striprtf.striprtf import rtf_to_text

# PDF ‚Üí —Ç–µ–∫—Å—Ç
def process_pdf(path: str) -> str:
    reader = PdfReader(path)
    text = []
    for page in reader.pages:
        text.append(page.extract_text() or "")
    return "\n".join(text)

# DOCX ‚Üí —Ç–µ–∫—Å—Ç
def process_docx(path: str) -> str:
    doc = Document(path)
    return "\n".join([p.text for p in doc.paragraphs])

# RTF ‚Üí —Ç–µ–∫—Å—Ç
def process_rtf(path: str) -> str:
    """
    –ß–∏—Ç–∞–µ—Ç RTF-—Ñ–∞–π–ª –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —á–∏—Å—Ç—ã–π —Ç–µ–∫—Å—Ç.
    –†–∞–±–æ—Ç–∞–µ—Ç –±–µ–∑ Pandoc.
    """
    with open(path, "r", encoding="utf-8") as f:
        content = f.read()
    text = rtf_to_text(content)
    return text

# TXT ‚Üí —Ç–µ–∫—Å—Ç
def process_txt(path: str) -> str:
    with open(path, "r", encoding="utf-8") as f:
        return f.read()

async def process_file_and_gpt(path: str, bot: Bot, user_id: int|str, vac_text: str):
    ext = path.split(".")[-1].lower()
    try:
        if ext == "pdf":
            text = process_pdf(path)
        elif ext == "docx":
            text = process_docx(path)
        elif ext == "rtf":
            text = process_rtf(path)
        elif ext == "txt":
            text = process_txt(path)
        else:
            await bot.send_message(user_id, f"‚ö†Ô∏è –§–æ—Ä–º–∞—Ç {ext} –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è: {path}")
            return
        
        text = asyncio.create_task(background_sverka(resume_text=text, vacancy_text=vac_text, bot=bot, user_id=user_id))
        
        os.remove(path)
    except Exception as e:
        await bot.send_message(user_id, f"‚ùå –û—à–∏–±–∫–∞ –≤ {path}: {e}")
        
        
async def background_sverka(resume_text: str, vacancy_text: str, bot: Bot, user_id: int|str):
    try:
        result = await asyncio.to_thread(sverka_vac_and_resume_json, vacancy_text, resume_text)
        
        if result:
            result = display_analysis(result)
            # –ï—Å–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –±–æ–ª—å—à–æ–π, –º–æ–∂–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å –ø–æ —á–∞—Å—Ç—è–º
            for i in range(0, len(result), 4096):
                await bot.send_message(user_id, result[i:i+4096], parse_mode="HTML")
        else:
            await bot.send_message(user_id, "‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–≤–µ—Ä–∫–µ –≤–∞–∫–∞–Ω—Å–∏–∏")
    except Exception as e:
        await bot.send_message(user_id, f"üî• –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–≤–µ—Ä–∫–µ: {e}")
        
        
        
        
        
        
import json

def display_analysis(json_data) -> str:
    
    processed_data = json_data
    if isinstance(processed_data, str):
        clean_str = processed_data.strip()
        if clean_str.startswith('```json'):
            clean_str = clean_str[len('```json'):].strip()
        if clean_str.endswith('```'):
            clean_str = clean_str[:-len('```')].strip()
        try:
            data = json.loads(clean_str)
        except json.JSONDecodeError:
            return "–û—à–∏–±–∫–∞: –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç JSON –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏."
    else:
        data = processed_data

    lines = []

    def append_field(key, value, indent=0):
        prefix = " " * indent
        val_str = value if value else "–Ω–µ —É–∫–∞–∑–∞–Ω–æ"
        lines.append(f"{prefix}{key}: {val_str}")

    # --- –í–ê–ö–ê–ù–°–ò–Ø ---
    lines.append("\n" + "="*15 + " üìù –í–ê–ö–ê–ù–°–ò–Ø " + "="*15)
    vacancy = data.get("vacancy", {})
    if vacancy:
        pos_id = f"(ID: {vacancy.get('vacancy_id')})" if vacancy.get('vacancy_id') else ""
        append_field("–ü–æ–∑–∏—Ü–∏—è", f"{vacancy.get('position')} {pos_id}")
        append_field("–ì—Ä–µ–π–¥", vacancy.get("grade"))
        append_field("–§–æ—Ä–º–∞—Ç —Ä–∞–±–æ—Ç—ã", vacancy.get("format"))
        loc = f"–õ–æ–∫–∞—Ü–∏—è: {vacancy.get('location')}, –ì—Ä–∞–∂–¥–∞–Ω—Å—Ç–≤–æ: {vacancy.get('citizenship')}, –ü–æ—è—Å: {vacancy.get('timezone')}"
        append_field("–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –ª–æ–∫–∞—Ü–∏–∏", loc)
        append_field("–ö–æ–Ω—Ç–∞–∫—Ç", vacancy.get("manager_nick"))

    # --- –ö–ê–ù–î–ò–î–ê–¢ ---
    lines.append("\n" + "="*15 + " üë§ –ö–ê–ù–î–ò–î–ê–¢ " + "="*15)
    candidate = data.get("candidate", {})
    if candidate:
        append_field("–§–ò–û", candidate.get("full_name"))
        append_field("–î–∞—Ç–∞ —Ä–æ–∂–¥–µ–Ω–∏—è", candidate.get("birth_date"))
        append_field("–õ–æ–∫–∞—Ü–∏—è", f"{candidate.get('city')}, {candidate.get('country')}")
        append_field("–ü–æ–∑–∏—Ü–∏—è", candidate.get("position"))

        lines.append("\n  –û–ø—ã—Ç —Ä–∞–±–æ—Ç—ã:")
        experience = candidate.get("experience", [])
        if experience:
            for exp in experience:
                lines.append(f"    - –ö–æ–º–ø–∞–Ω–∏—è: {exp.get('company_name', '–Ω–µ —É–∫–∞–∑–∞–Ω–æ')} ({exp.get('period', 'N/A')})")
                lines.append(f"      –î–æ–ª–∂–Ω–æ—Å—Ç—å: {exp.get('role', '–Ω–µ —É–∫–∞–∑–∞–Ω–æ')}")
                for proj in exp.get("projects", []):
                    lines.append(f"      –ü—Ä–æ–µ–∫—Ç: {proj.get('description', '–û–ø–∏—Å–∞–Ω–∏–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç')}")
                    lines.append("        –û–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏:")
                    for resp in proj.get("responsibilities", []):
                        lines.append(f"          ‚Ä¢ {resp}")
        else:
            lines.append("    –û–ø—ã—Ç —Ä–∞–±–æ—Ç—ã –Ω–µ —É–∫–∞–∑–∞–Ω.")

        lines.append("\n  –°—Ç–µ–∫ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π: " + ', '.join(candidate.get("tech_stack", [])) or "–Ω–µ —É–∫–∞–∑–∞–Ω")

    # --- –¢–ê–ë–õ–ò–¶–ê –°–û–û–¢–í–ï–¢–°–¢–í–ò–Ø ---
    lines.append("\n" + "="*12 + " ‚úÖ –¢–ê–ë–õ–ò–¶–ê –°–û–û–¢–í–ï–¢–°–¢–í–ò–Ø " + "="*12)
    compliance = data.get("comparison_tables", {})
    status_map = {
        "–î–∞": "‚úÖ",
        "–ù–µ—Ç (—É—Ç–æ—á–Ω–∏—Ç—å)": "‚ùì",
        "–ù–µ—Ç (—Ç–æ—á–Ω–æ –Ω–µ—Ç)": "‚ùå"
    }

    lines.append("\n  –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è:")
    must_haves = compliance.get("must_have", [])
    if must_haves:
        for req in must_haves:
            icon = status_map.get(req.get("status"), '‚ñ´Ô∏è')
            lines.append(f"    {icon} {req.get('requirement')}")
            lines.append(f"      ‚îî‚îÄ –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π: {req.get('comment')}")
    else:
        lines.append("    –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –Ω–µ —É–∫–∞–∑–∞–Ω—ã.")

    lines.append("\n  –ë—É–¥–µ—Ç –ø–ª—é—Å–æ–º:")
    nice_to_haves = compliance.get("nice_to_have", [])
    if nice_to_haves:
        for req in nice_to_haves:
            icon = status_map.get(req.get("status"), '‚ñ´Ô∏è')
            lines.append(f"    {icon} {req.get('requirement')}")
            lines.append(f"      ‚îî‚îÄ –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π: {req.get('comment')}")
    else:
        lines.append("    –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –Ω–µ —É–∫–∞–∑–∞–Ω—ã.")

    # --- –ò–¢–û–ì ---
    lines.append("\n" + "="*17 + " üèÅ –ò–¢–û–ì " + "="*17)
    summary = data.get("candidate_result", {})
    if summary:
        append_field("–í–µ—Ä–¥–∏–∫—Ç", summary.get("result_status"))
        append_field("–ó–∞—Ä–ø–ª–∞—Ç–Ω—ã–µ –æ–∂–∏–¥–∞–Ω–∏—è", summary.get("salary_expectations"))

    lines.append("="*41)

    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –≥–æ—Ç–æ–≤—ã–π —Ç–µ–∫—Å—Ç
    return "\n".join(lines)





