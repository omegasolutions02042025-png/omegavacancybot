from docx import Document
from PyPDF2 import PdfReader
import pypandoc
from aiogram import Bot
import os
from gpt_gimini import sverka_vac_and_resume_json, generate_mail_for_candidate_finalist, generate_mail_for_candidate_utochnenie, generate_mail_for_candidate_otkaz, generate_cover_letter_for_client
import asyncio
from funcs import format_candidate_json_str
from striprtf.striprtf import rtf_to_text
from db import add_otkonechenie_resume, add_final_resume, add_utochnenie_resume
from kb import utochnit_prichinu_kb
from dotenv import load_dotenv
import textract
from db import add_save_resume
from telethon_bot import ADMIN_ID
load_dotenv()



CLIENT_CHANNEL = os.getenv('CLIENT_CHANNEL')

def process_doc(path: str) -> str:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ .doc (—Å—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç Word 97‚Äì2003) —Å –ø–æ–º–æ—â—å—é textract.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—á–∏—â–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –±–µ–∑ –ø—É—Å—Ç—ã—Ö —Å—Ç—Ä–æ–∫.
    """
    try:
        text = textract.process(path).decode("utf-8", errors="ignore")
        lines = [line.strip() for line in text.splitlines() if line.strip()]
        return "\n".join(lines)
    except FileNotFoundError:
        print(f"‚ö†Ô∏è –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {path}")
        return ""
    except textract.exceptions.ShellError as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ textract –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {path}: {e}")
        return ""
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ DOC-—Ñ–∞–π–ª–∞ {path}: {e}")
        return ""


# PDF ‚Üí —Ç–µ–∫—Å—Ç
def process_pdf(path: str) -> str:
    """
    –ù–∞–¥—ë–∂–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ PDF:
    1) pdfminer.six
    2) PyPDF2/pypdf (—Å –ø–æ–ø—ã—Ç–∫–æ–π strict=False, –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ)
    3) –†–µ–º–æ–Ω—Ç PDF —á–µ—Ä–µ–∑ pikepdf –∏ –ø–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ (pdfminer/textract)
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—á–∏—â–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –±–µ–∑ –ø—É—Å—Ç—ã—Ö —Å—Ç—Ä–æ–∫.
    """
    def _clean(txt: str) -> str:
        return "\n".join([ln.strip() for ln in (txt or "").splitlines() if ln.strip()]).strip()

    # --- 1) pdfminer.six ---
    try:
        from pdfminer.high_level import extract_text as pdfminer_extract_text
        txt = _clean(pdfminer_extract_text(path) or "")
        # –µ—Å–ª–∏ —Ç–µ–∫—Å—Ç–∞ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ ‚Äî —ç—Ç–æ–≥–æ —Ö–≤–∞—Ç–∞–µ—Ç
        if len(txt) > 200:
            return txt
        # –∏–Ω–∞—á–µ –Ω–µ –≤—ã—Ö–æ–¥–∏–º ‚Äî –ø–æ–ø—Ä–æ–±—É–µ–º –¥—Ä—É–≥–∏–µ —Å–ø–æ—Å–æ–±—ã (–º–æ–∂–µ—Ç –±—ã—Ç—å —Å–∫–∞–Ω –∏–ª–∏ ¬´–∫—Ä–∏–≤–æ–π¬ª PDF)
    except Exception as e:
        print(f"‚ö†Ô∏è pdfminer.six –Ω–µ —Å–ø—Ä–∞–≤–∏–ª—Å—è: {e}")

    # --- 2) PyPDF2 / pypdf ---
    try:
        from PyPDF2 import PdfReader
        try:
            # pypdf 3.x: –ø–∞—Ä–∞–º–µ—Ç—Ä strict –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç
            reader = PdfReader(path)
        except TypeError:
            # PyPDF2 1.x/2.x: –º–æ–∂–Ω–æ –æ—Å–ª–∞–±–∏—Ç—å —Å—Ç—Ä–æ–≥–æ—Å—Ç—å
            reader = PdfReader(path, strict=False)
        pages_text = []
        for p in reader.pages:
            t = p.extract_text() or ""
            if t.strip():
                pages_text.append(t)
        txt = _clean("\n".join(pages_text))
        if txt:
            return txt
    except Exception as e:
        # –∏–º–µ–Ω–Ω–æ –≤–∞—à –∫–µ–π—Å
        if "Odd-length string" in str(e):
            print("‚ö†Ô∏è PyPDF2: Odd-length string ‚Äî –ø–æ–ø—Ä–æ–±—É—é –æ—Ç—Ä–µ–º–æ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å PDF —á–µ—Ä–µ–∑ pikepdf‚Ä¶")
        else:
            print(f"‚ö†Ô∏è PyPDF2/pypdf —É–ø–∞–ª: {e}")

    # --- 3) –†–µ–º–æ–Ω—Ç —á–µ—Ä–µ–∑ pikepdf –∏ –ø–æ–≤—Ç–æ—Ä ---
    try:
        import tempfile, pikepdf
        with pikepdf.open(path) as pdf:
            with tempfile.NamedTemporaryFile(suffix=".pdf", delete=False) as tmp:
                pdf.save(tmp.name)
                repaired_path = tmp.name

        # —Å–Ω–æ–≤–∞ –ø–æ–ø—Ä–æ–±—É–µ–º pdfminer
        try:
            from pdfminer.high_level import extract_text as pdfminer_extract_text
            txt = _clean(pdfminer_extract_text(repaired_path) or "")
            if txt:
                return txt
        except Exception as e:
            print(f"‚ö†Ô∏è pdfminer –ø–æ—Å–ª–µ —Ä–µ–º–æ–Ω—Ç–∞ –Ω–µ —Å–ø—Ä–∞–≤–∏–ª—Å—è: {e}")

        # —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ñ–æ–ª–ª–±—ç–∫: textract (–º–æ–∂–µ—Ç –¥–µ—Ä–Ω—É—Ç—å tesseract, –µ—Å–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω)
        try:
            import textract
            raw = textract.process(repaired_path).decode("utf-8", errors="ignore")
            txt = _clean(raw)
            return txt
        except Exception as e:
            print(f"‚ùå textract —Ç–æ–∂–µ –Ω–µ —Å–º–æ–≥: {e}")

    except Exception as e:
        print(f"‚ùå –†–µ–º–æ–Ω—Ç PDF —á–µ—Ä–µ–∑ pikepdf –Ω–µ —É–¥–∞–ª—Å—è: {e}")

    return ""


# DOCX ‚Üí —Ç–µ–∫—Å—Ç
def process_docx(path: str) -> str:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –≤–µ—Å—å —Ç–µ–∫—Å—Ç –∏–∑ .docx, –≤–∫–ª—é—á–∞—è —Ç–∞–±–ª–∏—Ü—ã –∏ –≤–ª–æ–∂–µ–Ω–Ω—ã–µ —è—á–µ–π–∫–∏.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–±—ä–µ–¥–∏–Ω—ë–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç.
    """
    try:
        doc = Document(path)
        texts = []

        # --- –ü–∞—Ä–∞–≥—Ä–∞—Ñ—ã ---
        for paragraph in doc.paragraphs:
            if paragraph.text.strip():
                texts.append(paragraph.text.strip())

        # --- –¢–∞–±–ª–∏—Ü—ã ---
        for table in doc.tables:
            for row in table.rows:
                for cell in row.cells:
                    cell_text = cell.text.strip()
                    if cell_text:
                        texts.append(cell_text)

        # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –∏ –æ–±—ä–µ–¥–∏–Ω—è–µ–º
        text = "\n".join(dict.fromkeys(texts))
        return text.strip()

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è DOCX: {e}")
        return ""

# RTF ‚Üí —Ç–µ–∫—Å—Ç
def process_rtf(path: str) -> str:
    """
    –ß–∏—Ç–∞–µ—Ç RTF-—Ñ–∞–π–ª –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —á–∏—Å—Ç—ã–π —Ç–µ–∫—Å—Ç.
    –†–∞–±–æ—Ç–∞–µ—Ç –±–µ–∑ Pandoc.
    """
    with open(path, "r", encoding="utf-8") as f:
        content = f.read()
    text = rtf_to_text(content)
    return text

# TXT ‚Üí —Ç–µ–∫—Å—Ç
def process_txt(path: str) -> str:
    with open(path, "r", encoding="utf-8") as f:
        return f.read()

async def process_file_and_gpt(path: str, bot: Bot, user_id: int|str, vac_text: str, file_name: str):
    ext = path.split(".")[-1].lower()
    
    try:
        if ext == "pdf":
            text = process_pdf(path)
        elif ext == "docx":
            text = process_docx(path)
        elif ext == "doc":
            text = process_doc(path)
        elif ext == "rtf":
            text = process_rtf(path)
        elif ext == "txt":
            text = process_txt(path)
        else:
            await bot.send_message(user_id, f"‚ö†Ô∏è –§–æ—Ä–º–∞—Ç {ext} –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è: {path}")
            return
        
        text_gpt = await background_sverka(resume_text=text, vacancy_text=vac_text, bot=bot, user_id=user_id, file_name=file_name)
        candidate_name = text_gpt.get("candidate")
        await add_save_resume(candidate_name, text)
        
        os.remove(path)
    except Exception as e:
        await bot.send_message(user_id, f"‚ùå –û—à–∏–±–∫–∞ –≤ {path}: {e}")
    finally:
        return text_gpt or None
        
async def background_sverka(resume_text: str, vacancy_text: str, bot: Bot, user_id: int|str, file_name: str):
    try:
        result_gpt = await sverka_vac_and_resume_json(resume_text, vacancy_text, file_name)
        
        if result_gpt:
            result = display_analysis(result_gpt)
            result_gpt = clean_json(result_gpt)
            verdict = result_gpt.get("summary").get("verdict")
            candidate = result_gpt.get("candidate").get("full_name")
            
            return {'candidate': candidate, 'verdict': verdict, 'sverka_text': result, 'candidate_json': result_gpt}
        else:
            await bot.send_message(ADMIN_ID, "‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–≤–µ—Ä–∫–µ –≤–∞–∫–∞–Ω—Å–∏–∏")
    except Exception as e:
        await bot.send_message(ADMIN_ID, f"üî• –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–≤–µ—Ä–∫–µ: {e}")
        return None
    
    
        
        
        

import json


def clean_json(json_data):
    if isinstance(json_data, str):
        clean_str = json_data.strip()
        if clean_str.startswith('```json'):
            clean_str = clean_str[len('```json'):].strip()
        if clean_str.endswith('```'):
            clean_str = clean_str[:-len('```')].strip()
        
        try:
            data = json.loads(clean_str)
        except json.JSONDecodeError:
            return "–û—à–∏–±–∫–∞: –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç JSON –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏."
    else:
        data = json_data
    return data

def display_analysis(json_data):
    """
    –ü—Ä–∏–Ω–∏–º–∞–µ—Ç JSON-—Å—Ç—Ä–æ–∫—É –∏–ª–∏ —Å–ª–æ–≤–∞—Ä—å Python –∏ –í–û–ó–í–†–ê–©–ê–ï–¢
    —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç—á–µ—Ç, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π –ò–º—è –∫–∞–Ω–¥–∏–¥–∞—Ç–∞, "–¢–∞–±–ª–∏—Ü—É —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è" –∏ "–ò—Ç–æ–≥".
    –ï—Å–ª–∏ –ø–æ–ª–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç, –≤—ã–≤–æ–¥–∏—Ç '‚ùå'.
    –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É–¥–∞–ª—è–µ—Ç –º–∞—Ä–∫–µ—Ä—ã –±–ª–æ–∫–∞ –∫–æ–¥–∞ ```json –∏ ```.
    """
    processed_data = json_data
    output_lines = []  # –°–ø–∏—Å–æ–∫ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –≤—Å–µ—Ö —Å—Ç—Ä–æ–∫ –æ—Ç—á–µ—Ç–∞

    # --- –ë–ª–æ–∫ –æ—á–∏—Å—Ç–∫–∏ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö ---
    processed_data = clean_json(processed_data)
    data = processed_data

    # –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ–ª—è "–∫–ª—é—á: –∑–Ω–∞—á–µ–Ω–∏–µ"
    def format_field(key, value):
        val_str = value if value else "‚ùå"
        return f"{key}: {val_str}"

    # --- –ö–ê–ù–î–ò–î–ê–¢ (—Ç–æ–ª—å–∫–æ –§–ò–û) ---
    output_lines.append("="*15 + " üë§ –ö–ê–ù–î–ò–î–ê–¢ " + "="*15)
    candidate = data.get("candidate", {})
    output_lines.append(format_field("–§–ò–û", candidate.get('full_name')))
    output_lines.append(format_field("‚Äî–î–∞—Ç–∞ —Ä–æ–∂–¥–µ–Ω–∏—è", candidate.get('birth_date').get('date')))
    output_lines.append(format_field("‚Äî–ó–∞—Ä–ø–ª–∞—Ç–Ω—ã–µ –æ–∂–∏–¥–∞–Ω–∏—è", data.get('summary').get('salary_expectations')))
    output_lines.append(format_field("‚Äî–õ–æ–∫–∞—Ü–∏—è", candidate.get('location').get('city')))
    output_lines.append(format_field("‚Äî–°—Ç–µ–∫ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π", ", ".join(candidate.get('tech_stack'))) )


    # --- –¢–ê–ë–õ–ò–¶–ê –°–û–û–¢–í–ï–¢–°–¢–í–ò–Ø ---
    output_lines.append("\n" + "="*12 + " ‚úÖ –¢–ê–ë–õ–ò–¶–ê –°–û–û–¢–í–ï–¢–°–¢–í–ò–Ø " + "="*12)
    compliance = data.get("compliance_check", {})
    status_map = { "–î–∞": "‚úÖ", "–ù–µ—Ç (—Ç—Ä–µ–±—É–µ—Ç—Å—è —É—Ç–æ—á–Ω–µ–Ω–∏–µ)": "‚ö†Ô∏è", "–ù–µ—Ç (—Ç–æ—á–Ω–æ –Ω–µ—Ç)": "‚ùå" }
    
    must_haves = compliance.get('must_have')
    if must_haves:
        for req in must_haves:
            icon = status_map.get(req.get('status'), '‚ñ´Ô∏è')
            if req.get('status') == "–ù–µ—Ç (—Ç—Ä–µ–±—É–µ—Ç—Å—è —É—Ç–æ—á–Ω–µ–Ω–∏–µ)" or req.get('status') == "–ù–µ—Ç (—Ç–æ—á–Ω–æ –Ω–µ—Ç)":
                output_lines.append(f"    {icon} {req.get('requirement')}")
                output_lines.append(f"({req.get('comment').replace('‚ö†Ô∏è', '').replace('‚ùå', '')})\n")
            else:
                output_lines.append(f"    {icon} {req.get('requirement')}\n")


    nice_to_haves = compliance.get('nice_to_have')
    if nice_to_haves:
        for req in nice_to_haves:
            icon = status_map.get(req.get('status'), '‚ñ´Ô∏è')
            if req.get('status') == "–ù–µ—Ç (—Ç—Ä–µ–±—É–µ—Ç—Å—è —É—Ç–æ—á–Ω–µ–Ω–∏–µ)" or req.get('status') == "–ù–µ—Ç (—Ç–æ—á–Ω–æ –Ω–µ—Ç)":
                output_lines.append(f"    {icon} {req.get('requirement')}")
                output_lines.append(f"({req.get('comment').replace('‚ö†Ô∏è', '').replace('‚ùå', '')})\n")
            else:
                output_lines.append(f"    {icon} {req.get('requirement')}\n")   

    # --- –ò–¢–û–ì ---
    output_lines.append("\n" + "="*17 + " üèÅ –ò–¢–û–ì " + "="*17)
    summary = data.get("summary", {})
    if summary:
        output_lines.append(format_field("–í–µ—Ä–¥–∏–∫—Ç", summary.get('verdict')))
    output_lines.append("="*41)

    return "\n".join(output_lines)




def create_finalists_table(finalists: list[dict]):
  """
  –°–æ–∑–¥–∞–µ—Ç —Ç–∞–±–ª–∏—Ü—É —Ñ–∏–Ω–∞–ª–∏—Å—Ç–æ–≤ –≤ —Ñ–æ—Ä–º–∞—Ç–µ Markdown.

  Args:
    finalists: –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π, –≥–¥–µ –∫–∞–∂–¥—ã–π —Å–ª–æ–≤–∞—Ä—å –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Ñ–∏–Ω–∞–ª–∏—Å—Ç–∞
               —Å –∫–ª—é—á–∞–º–∏ 'name', 'grade', 'location', 'stack', –∏ 'salary'.

  Returns:
    –°—Ç—Ä–æ–∫–∞ —Å —Ç–∞–±–ª–∏—Ü–µ–π –≤ —Ñ–æ—Ä–º–∞—Ç–µ Markdown.
  """

  
  
  header = "| –§–ò–û/–§–ò | –ì—Ä–µ–π–¥ | –õ–æ–∫–∞—Ü–∏—è | –ö–ª—é—á–µ–≤–æ–π —Å—Ç–µ–∫ | –ó–∞—Ä–ø–ª–∞—Ç–Ω—ã–µ –æ–∂–∏–¥–∞–Ω–∏—è |\n"
  separator = "|---|---|---|---|---|\n"
  body = ""
  for finalist in finalists:
    if isinstance(finalist, str):
      continue
    candidate = finalist.get("candidate", {})
    summary = finalist.get("summary", {})
    verdict = summary.get("verdict", "")
    if verdict == "–ü–æ–ª–Ω–æ—Å—Ç—å—é –ø–æ–¥—Ö–æ–¥–∏—Ç":
      body += f"| {candidate['full_name'] or '‚ùå'} | {candidate['grade_and_position'] or '‚ùå'} | {candidate['location']['city'] or '‚ùå'} | {summary['salary_expectations'] or '‚ùå'} |{summary['verdict'] or '‚ùå'}\n"
    elif verdict == "–ß–∞—Å—Ç–∏—á–Ω–æ –ø–æ–¥—Ö–æ–¥–∏—Ç (–Ω—É–∂–Ω—ã —É—Ç–æ—á–Ω–µ–Ω–∏—è)":
      body += f"| {candidate['full_name'] or '‚ùå'} | {candidate['grade_and_position'] or '‚ùå'} | {candidate['location']['city'] or '‚ùå'} | {summary['salary_expectations'] or '‚ùå'} |{summary['verdict'] or '‚ùå'}\n"
    elif verdict == "–ù–µ –ø–æ–¥—Ö–æ–¥–∏—Ç":
      body += f"| {candidate['full_name'] or '‚ùå'} | {candidate['grade_and_position'] or '‚ùå'} | {candidate['location']['city'] or '‚ùå'} | {summary['salary_expectations'] or '‚ùå'} |{summary['verdict'] or '‚ùå'}\n"
  return header + separator + body



    
    
async def create_mails(finalist: dict, user_name: str, vacancy: str):
    try:
    
      if isinstance(finalist, str):
        print("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö —Ñ–∏–Ω–∞–ª–∏—Å—Ç–∞")
        return None
      summary = finalist.get("summary", {})
      verdict = summary.get("verdict", "")
      if verdict == "–ü–æ–ª–Ω–æ—Å—Ç—å—é –ø–æ–¥—Ö–æ–¥–∏—Ç":
        res = await generate_mail_for_candidate_finalist(finalist, user_name)
        return res
      elif verdict == "–ß–∞—Å—Ç–∏—á–Ω–æ –ø–æ–¥—Ö–æ–¥–∏—Ç (–Ω—É–∂–Ω—ã —É—Ç–æ—á–Ω–µ–Ω–∏—è)":
        res = await generate_mail_for_candidate_utochnenie(finalist, user_name, vacancy)
        return res
      elif verdict == "–ù–µ –ø–æ–¥—Ö–æ–¥–∏—Ç":
        res = await generate_mail_for_candidate_otkaz(finalist, user_name)
        return res
    except Exception as e:
      print(f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –ø–∏—Å—å–º–∞: {e}")
      return None